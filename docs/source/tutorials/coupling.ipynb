{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be250fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.nnx as nnx\n",
    "import flax.typing as ftp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax_autovmap import auto_vmap\n",
    "\n",
    "import lfx\n",
    "\n",
    "rngs = nnx.Rngs(default=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b17387",
   "metadata": {},
   "source": [
    "# General coupling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b4613",
   "metadata": {},
   "source": [
    "In coupling layers, some subset of values are updated bijectively conditioned on the other values.\n",
    "\n",
    "For some choices this can be implemented straight-forwardly.\n",
    "In real NVP, for example, we can emply binary masks and do the transformation directly.\n",
    "\n",
    "More abstractly, we may have a bijection $x \\mapsto f(x; \\theta)$ that updates the *active* values $x$.\n",
    "To turn this into a coupling layer generally, we want to take $\\theta(y)$ given passive values $y$.\n",
    "We can do this manually, of course.\n",
    "\n",
    "But there is also a convenience class implemented that:\n",
    "- Converts any module (or state) into the map $\\theta \\mapsto (x \\mapsto f(x; \\theta))$\n",
    "- Extracts the total size and shapes of parameters (such that $\\theta$ can be one large array, a list of parameters, or a dict of parameters)\n",
    "- Handle automatic vmap over batch dimension (since $\\theta(y)$ would generally introduce a batch dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00854334",
   "metadata": {},
   "source": [
    "## Example: single spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afb678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lfx.bijections.splines.MonotoneRQSpline(3, 10, rngs=rngs)\n",
    "model_factory = lfx.bijections.coupling.ModuleReconstructor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883ce647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(87)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can provide single 1d array of parameters of this size\n",
    "model_factory.params_total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf36cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heights': ShapedArray(float32[3,10]),\n",
       " 'slopes': ShapedArray(float32[3,9]),\n",
       " 'widths': ShapedArray(float32[3,10])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also provide dictionary which matches this structure\n",
    "model_factory.params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173440f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ShapedArray(float32[3,10]),\n",
       " ShapedArray(float32[3,9]),\n",
       " ShapedArray(float32[3,10])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or \"leaves\" of the corresponding pytree\n",
    "model_factory.params_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd5826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('float32'), dtype('float32'), dtype('float32')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other convenience attributes also available\n",
    "model_factory.params_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6f5d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 10), (3, 9), (3, 10)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other convenience attributes also available\n",
    "model_factory.params_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93bebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heights': (3, 10), 'slopes': (3, 9), 'widths': (3, 10)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other convenience attributes also available\n",
    "model_factory.params_shape_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd883324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caveat: need to be careful if parameters are complex (not fully supported)\n",
    "model_factory.has_complex_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabcebe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ],\n",
       "        [0.44812006, 0.74798065, 0.3836273 ]], dtype=float32),\n",
       " Array([1.6312416, 1.6312416, 1.6312416, 1.6312416, 1.6312416, 1.6312416,\n",
       "        1.6312416, 1.6312416, 1.6312416, 1.6312416], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy array of parameters (would usually be/depend on the output of some NN)\n",
    "params_array = np.random.normal(size=(model_factory.params_total_size,))\n",
    "\n",
    "# example inputs\n",
    "x = np.ones((10, 3)) / 2\n",
    "lp = np.zeros((10,))\n",
    "\n",
    "model = model_factory.from_array(params_array)\n",
    "model.forward(x, lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79801c",
   "metadata": {},
   "source": [
    "Note that in the above example, the input is batched (which is fine because the model itself supports that),\n",
    "but the parameters are not batched.\n",
    "If we have batched parameters, we effectively have a \"stack\" of models.\n",
    "Depending on the bijection, this may be nontrivial to handle (it is trivial for real NVP where the affine transformation is trivially broadcastable, but not e.g. for splines).\n",
    "\n",
    "`.auto_vmap_array`, `.auto_vmap_dict` and `.auto_vmap_leaves` effectively act like an instance of `model`, except that function calls add `params` as first argument and automatically vmap over these and the inputs.\n",
    "\n",
    "In addition, the ranks (i.e. dimensions) of the inputs need to be provided to know how vmap should be applied.\n",
    "This defaults to $(1, 0)$ which matches many NF cases (vector state and scalar log-density)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf55960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.41064703, 0.01066445, 0.2767329 ],\n",
       "        [0.37461302, 0.7361562 , 0.30834916],\n",
       "        [0.3074231 , 0.5192351 , 0.39163208],\n",
       "        [0.12614258, 0.47200948, 0.53802824],\n",
       "        [0.25864998, 0.53435785, 0.6444026 ],\n",
       "        [0.32224256, 0.8636802 , 0.35441762],\n",
       "        [0.43365756, 0.91749805, 0.17344713],\n",
       "        [0.7867354 , 0.49086675, 0.39499205],\n",
       "        [0.5754057 , 0.31122735, 0.48212758],\n",
       "        [0.67516726, 0.19719765, 0.654301  ]], dtype=float32),\n",
       " Array([1.0165834e+01, 5.0352812e-03, 1.0950508e+00, 6.2632942e+00,\n",
       "        6.2445688e+00, 7.2555504e+00, 4.3614316e+00, 7.4305475e-02,\n",
       "        1.3601456e+01, 5.1075807e+00], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add batch dimension to parameters\n",
    "p = np.random.normal(size=(10, model_factory.params_total_size))\n",
    "\n",
    "model_factory.auto_vmap_array.forward(p, x, lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f879bc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.41064703, 0.01066445, 0.2767329 ],\n",
       "        [0.37461302, 0.7361562 , 0.30834916],\n",
       "        [0.3074231 , 0.5192351 , 0.39163208],\n",
       "        [0.12614258, 0.47200948, 0.53802824],\n",
       "        [0.25864998, 0.53435785, 0.6444026 ],\n",
       "        [0.32224256, 0.8636802 , 0.35441762],\n",
       "        [0.43365756, 0.91749805, 0.17344713],\n",
       "        [0.7867354 , 0.49086675, 0.39499205],\n",
       "        [0.5754057 , 0.31122735, 0.48212758],\n",
       "        [0.67516726, 0.19719765, 0.654301  ]], dtype=float32),\n",
       " Array([1.0165834e+01, 5.0352812e-03, 1.0950508e+00, 6.2632942e+00,\n",
       "        6.2445688e+00, 7.2555504e+00, 4.3614316e+00, 7.4305475e-02,\n",
       "        1.3601456e+01, 5.1075807e+00], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explicitly provide input ranks\n",
    "autovmap_model = model_factory.auto_vmap_array\n",
    "\n",
    "autovmap_model.forward(p, x, lp, input_ranks=(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3648f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't really need to wrap this in jax.jit, but in prinicple avoids\n",
    "# allocating the parameters that are not used in the end\n",
    "@partial(jax.jit, static_argnums=(0, 1))\n",
    "def get_spline_template(size, knots):\n",
    "     # output not numerical, doesn't matter here\n",
    "    rngs = nnx.Rngs(0)\n",
    "\n",
    "    # define bijection\n",
    "    spline = lfx.bijections.splines.MonotoneRQSpline(size, knots, rngs=rngs)\n",
    "\n",
    "    # get reconstructor map params -> bijection\n",
    "    return lfx.bijections.coupling.ModuleReconstructor(spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a20a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_template = get_spline_template(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineCouplingLayer(lfx.Bijection):\n",
    "    def __init__(self, mask, embeds, depth, width, rngs):\n",
    "        self.embeds = nnx.Linear(mask.sum(), embeds, rngs=rngs)\n",
    "        self.spline_template = get_spline_template(mask.sum(), 10)\n",
    "        self.couplings = lfx.nn.simple_nets.SimpleResNet(\n",
    "            embeds, self.spline_template.params_total_size, width, depth,\n",
    "            final_kernel_init=nnx.initializers.normal(),\n",
    "            final_bias_init=nnx.initializers.zeros,\n",
    "            rngs=rngs)\n",
    "        self.mask = mask\n",
    "\n",
    "    def split(self, x):\n",
    "        return x[..., self.mask], x[..., ~self.mask]\n",
    "\n",
    "    def forward(self, x, log_density, **kwargs):\n",
    "        active, passive = self.split(x)\n",
    "        h = jnp.sin(self.embeds(passive))\n",
    "        params = self.couplings(h)\n",
    "        active, log_density = self.spline_template.auto_vmap_array.forward(\n",
    "            params, active, log_density)\n",
    "        x = x.at[..., self.mask].set(active)\n",
    "        return x, log_density\n",
    "\n",
    "    def reverse(self, x, log_density, **kwargs):\n",
    "        active, passive = self.split(x)\n",
    "        h = jnp.sin(self.embeds(passive))\n",
    "        params = self.couplings(h)\n",
    "        active, log_density = self.spline_template.auto_vmap_array.reverse(\n",
    "            params, active, log_density)\n",
    "        x = x.at[..., self.mask].set(active)\n",
    "        return x, log_density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43e12a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([True, False])\n",
    "\n",
    "layers = []\n",
    "\n",
    "for _ in range(5):\n",
    "    layers.append(SplineCouplingLayer(mask, 12, 2, 32, rngs=rngs))\n",
    "    mask = ~mask\n",
    "\n",
    "model = lfx.Chain(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfe10a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001],\n",
       "        [0.9999998, 1.0000001]], dtype=float32),\n",
       " Array([-8.821487e-06, -8.821487e-06, -8.821487e-06, -8.821487e-06,\n",
       "        -8.821487e-06, -8.821487e-06, -8.821487e-06, -8.821487e-06,\n",
       "        -8.821487e-06, -8.821487e-06], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(jnp.ones((10, 2)), jnp.zeros((10,)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
