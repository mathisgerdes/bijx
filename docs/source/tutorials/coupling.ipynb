{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be250fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.nnx as nnx\n",
    "import flax.typing as ftp\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from jax_autovmap import auto_vmap\n",
    "from einops import rearrange\n",
    "\n",
    "import lfx\n",
    "\n",
    "rngs = nnx.Rngs(default=0)\n",
    "\n",
    "lfx.utils.load_shapes_magic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b17387",
   "metadata": {},
   "source": [
    "# General coupling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b4613",
   "metadata": {},
   "source": [
    "In coupling layers, some subset of values are updated bijectively conditioned on the other values.\n",
    "\n",
    "For some choices this can be implemented straight-forwardly.\n",
    "In real NVP, for example, we can emply binary masks and do the transformation directly.\n",
    "\n",
    "More abstractly, we may have a bijection $x \\mapsto f(x; \\theta)$ that updates the *active* values $x$.\n",
    "To turn this into a coupling layer generally, we want to take $\\theta(y)$ given passive values $y$.\n",
    "We can do this manually, of course.\n",
    "\n",
    "But there is also a convenience class implemented that:\n",
    "- Converts any module (or state) into the map $\\theta \\mapsto (x \\mapsto f(x; \\theta))$\n",
    "- Extracts the total size and shapes of parameters (such that $\\theta$ can be one large array, a list of parameters, or a dict of parameters)\n",
    "- Handle automatic vmap over batch dimension (since $\\theta(y)$ would generally introduce a batch dimension)\n",
    "\n",
    "[Note: for most (all?) scalar bijections the reconstructor is enough, even without auto_vmap, as parameter broadcasting is supported]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00854334",
   "metadata": {},
   "source": [
    "## Example: single spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afb678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform three entries of an array independently -> shape (3,)\n",
    "model = lfx.bijections.splines.MonotoneRQSpline(10, (3,), rngs=rngs)\n",
    "model_factory = lfx.bijections.coupling.ModuleReconstructor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883ce647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(84)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can provide single 1d array of parameters of this size\n",
    "model_factory.params_total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf36cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heights': ShapedArray(float32[3,9]),\n",
       " 'slopes': ShapedArray(float32[3,9]),\n",
       " 'widths': ShapedArray(float32[3,10])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also provide dictionary which matches this structure\n",
    "model_factory.params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173440f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ShapedArray(float32[3,9]),\n",
       " ShapedArray(float32[3,9]),\n",
       " ShapedArray(float32[3,10])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or \"leaves\" of the corresponding pytree\n",
    "model_factory.params_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd5826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('float32'), dtype('float32'), dtype('float32')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other convenience attributes also available\n",
    "model_factory.params_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6f5d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 9), (3, 9), (3, 10)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other convenience attributes also available\n",
    "model_factory.params_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a93bebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'heights': (3, 9), 'slopes': (3, 9), 'widths': (3, 10)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some other convenience attributes also available\n",
    "model_factory.params_shape_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd883324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caveat: need to be careful if parameters are complex (not fully supported)\n",
    "model_factory.has_complex_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabcebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10, 3), (10,))\n"
     ]
    }
   ],
   "source": [
    "# dummy array of parameters (would usually be/depend on the output of some NN)\n",
    "params_array = np.random.normal(size=(model_factory.params_total_size,))\n",
    "\n",
    "# example inputs\n",
    "x = np.ones((10, 3)) / 2\n",
    "lp = np.zeros((10,))\n",
    "\n",
    "model = model_factory.from_params(params_array)\n",
    "%shapes model.forward(x, lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79801c",
   "metadata": {},
   "source": [
    "Note that in the above example, the input is batched (which is fine because the model itself supports that),\n",
    "but the parameters are not batched.\n",
    "If we have batched parameters, we effectively have a \"stack\" of models.\n",
    "Depending on the bijection, this may be nontrivial to handle (it is trivial for real NVP where the affine transformation is trivially broadcastable, but not e.g. for splines).\n",
    "\n",
    "If we provide the optional argument `auto_vmap=True` to `from_params`, the object effectively acts like an instance of `model`, except that function calls add `params` as first argument and automatically vmap over these and the inputs.\n",
    "\n",
    "In addition, the ranks (i.e. dimensions) of the inputs need to be provided to know how vmap should be applied.\n",
    "This defaults to $(0, 0)$ which matches the many NF cases (vector state and scalar log-density), but the splines are actually implemented to assume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf55960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10, 3), (10,))\n"
     ]
    }
   ],
   "source": [
    "# add batch dimension to parameters\n",
    "p = np.random.normal(size=(10, model_factory.params_total_size,))\n",
    "rec = model_factory.from_params(p, auto_vmap=True)\n",
    "\n",
    "# spline above was initialized to expect 1D inputs, not scalar, so need to specify\n",
    "%shapes rec.forward(x, lp, input_ranks=(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3648f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't really need to wrap this in jax.jit, but in prinicple avoids\n",
    "# allocating the parameters that are not used in the end\n",
    "@partial(jax.jit, static_argnums=(0, 1))\n",
    "def get_spline_template(size, knots):\n",
    "     # output not numerical, doesn't matter here\n",
    "    rngs = nnx.Rngs(0)\n",
    "\n",
    "    # define bijection\n",
    "    spline = lfx.bijections.splines.MonotoneRQSpline(knots, (size,), rngs=rngs)\n",
    "\n",
    "    # get reconstructor map params -> bijection\n",
    "    return lfx.bijections.coupling.ModuleReconstructor(spline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a03658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplineCouplingLayer(lfx.Bijection):\n",
    "    def __init__(self, mask, embeds, depth, width, rngs):\n",
    "\n",
    "        spline_template = get_spline_template(mask.sum(), 10)\n",
    "\n",
    "        resnet = lfx.nn.simple_nets.SimpleResNet(\n",
    "            embeds, spline_template.params_total_size, width, depth,\n",
    "            final_kernel_init=nnx.initializers.normal(),\n",
    "            final_bias_init=nnx.initializers.zeros,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        param_net = nnx.Sequential(\n",
    "            nnx.Linear(mask.sum(), embeds, rngs=rngs),\n",
    "            jnp.sin,\n",
    "            resnet,\n",
    "        )\n",
    "\n",
    "        mask = lfx.BinaryMask.from_boolean_mask(mask)\n",
    "\n",
    "        self.bijection = lfx.GeneralCouplingLayer(\n",
    "            param_net, mask, spline_template,\n",
    "            # by default assume bijections are scalar, but here the splines\n",
    "            # operate (independently) on entries of a 1D array\n",
    "            bijection_event_rank=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, log_density, **kwargs):\n",
    "        return self.bijection.forward(x, log_density, input_ranks=(1, 0), **kwargs)\n",
    "\n",
    "    def reverse(self, x, log_density, **kwargs):\n",
    "        return self.bijection.reverse(x, log_density, input_ranks=(1, 0), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43e12a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([True, False])\n",
    "\n",
    "layers = []\n",
    "\n",
    "for _ in range(5):\n",
    "    layers.append(SplineCouplingLayer(mask, 12, 2, 32, rngs=rngs))\n",
    "    mask = ~mask\n",
    "\n",
    "model = lfx.Chain(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe10a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10, 2), (10,))\n"
     ]
    }
   ],
   "source": [
    "%shapes model.forward(jnp.ones((10, 2)), jnp.zeros((10,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac921e91",
   "metadata": {},
   "source": [
    "Note that above, the fundamental transformation of splines was taken to operate on a whole array.\n",
    "In principle, it need not have applied independent operations per entry, which shows the generality of the coupling layer implementation.\n",
    "However, in this specific case, splines do act element wise.\n",
    "Some bijections in fact may only be defined on single scalar values.\n",
    "Below is the same example as above, but treating the \"array\" index as part of the \"batch\" index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14017d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knots = 11\n",
    "spline_template = lfx.ModuleReconstructor(\n",
    "      lfx.MonotoneRQSpline(knots, rngs=nnx.Rngs(0))\n",
    ")\n",
    "\n",
    "def spline_coupling_layer(mask, embeds, depth, width, rngs):\n",
    "\n",
    "        mask = lfx.BinaryMask.from_boolean_mask(mask)\n",
    "\n",
    "        count_active, count_passive = mask.counts\n",
    "        param_count = spline_template.params_total_size\n",
    "\n",
    "        resnet = lfx.nn.simple_nets.SimpleResNet(\n",
    "            embeds, count_active *param_count, width, depth,\n",
    "            final_kernel_init=nnx.initializers.normal(),\n",
    "            final_bias_init=nnx.initializers.zeros,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "\n",
    "        param_net = nnx.Sequential(\n",
    "            nnx.Linear(count_passive, embeds, rngs=rngs),\n",
    "            jnp.sin,\n",
    "            resnet,\n",
    "            lambda x: rearrange(x, '... (t b) -> ... t b', t=count_active),\n",
    "        )\n",
    "\n",
    "\n",
    "        return lfx.GeneralCouplingLayer(\n",
    "            param_net,\n",
    "            mask,\n",
    "            spline_template,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba42bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([True, False])\n",
    "\n",
    "layers = []\n",
    "\n",
    "for _ in range(5):\n",
    "    layers.append(spline_coupling_layer(mask, 12, 2, 32, rngs=rngs))\n",
    "    mask = ~mask\n",
    "\n",
    "model = lfx.Chain(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35805cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(jnp.ones((10, 2)), jnp.zeros((10,)))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c732bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualAffineCoupling(lfx.Bijection):\n",
    "    \"\"\"\n",
    "    Affine coupling layer.\n",
    "\n",
    "    Masking here is done by multiplication, not by indexing.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        space_shape = (16, 16)  # no channel/feature dim (add dummy axis below)\n",
    "\n",
    "        affine_flow = lfx.Chain([\n",
    "            lfx.ExpandDims(),\n",
    "            lfx.AffineCoupling(\n",
    "                lfx.SimpleConvNet(1, 2, rngs=rngs),\n",
    "                lfx.checker_mask(space_shape + (1,), True)),\n",
    "            lfx.AffineCoupling(\n",
    "                lfx.SimpleConvNet(1, 2, rngs=rngs),\n",
    "                lfx.checker_mask(space_shape + (1,), False)),\n",
    "            lfx.ExpandDims().invert(),\n",
    "        ])\n",
    "        ```\n",
    "\n",
    "    `net` should map: `x_f -> act`\n",
    "    such that `s, t = split(act, 2, -1)`\n",
    "    and `x_out = t + x_a * exp(s) + x_f`\n",
    "\n",
    "    Args:\n",
    "        net: Network that maps frozen features to s, t.\n",
    "        mask: BinaryMask to apply to input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net: nnx.Module, mask: lfx.BinaryMask, *, rngs=None):\n",
    "        self.mask = mask\n",
    "        self.net = net\n",
    "\n",
    "    @property\n",
    "    def mask_active(self):\n",
    "        return self.mask\n",
    "\n",
    "    @property\n",
    "    def mask_frozen(self):\n",
    "        return ~self.mask\n",
    "\n",
    "    def forward(self, x, log_density):\n",
    "        x_frozen = self.mask_frozen * x\n",
    "        x_active = self.mask_active * x\n",
    "        activation = self.net(x_frozen)\n",
    "        s, t = jnp.split(activation, 2, -1)\n",
    "\n",
    "        fx = x_frozen + (self.mask_active * t) + x_active * jnp.exp(s)\n",
    "        axes = tuple(range(-len(self.mask.event_shape), 0))\n",
    "        log_jac = jnp.sum((self.mask_active * s), axis=axes)\n",
    "        return fx, log_density - log_jac\n",
    "\n",
    "    def reverse(self, fx, log_density):\n",
    "        fx_frozen = self.mask_frozen * fx\n",
    "        fx_active = self.mask_active * fx\n",
    "        activation = self.net(fx_frozen)\n",
    "        s, t = jnp.split(activation, 2, -1)\n",
    "        x = (fx_active - (self.mask_active * t)) * jnp.exp(-s) + fx_frozen\n",
    "        axes = tuple(range(-len(self.mask.event_shape), 0))\n",
    "        log_jac = jnp.sum((self.mask_active * s), axis=axes)\n",
    "        return x, log_density + log_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9143c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_shape = (16, 16)  # no channel/feature dim (add dummy axis below)\n",
    "\n",
    "affine_flow_1 = lfx.Chain(\n",
    "    lfx.ExpandDims(),\n",
    "    ManualAffineCoupling(\n",
    "        lfx.SimpleConvNet(1, 2, rngs=rngs),\n",
    "        lfx.checker_mask(space_shape + (1,), True)),\n",
    "    ManualAffineCoupling(\n",
    "        lfx.SimpleConvNet(1, 2, rngs=rngs),\n",
    "        lfx.checker_mask(space_shape + (1,), False)),\n",
    "    lfx.ExpandDims().invert(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7d08e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 16, 16), (2,))\n"
     ]
    }
   ],
   "source": [
    "%shapes affine_flow_1.forward(np.ones((2, 16, 16)), jnp.zeros((2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d17f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_affine_coupling(\n",
    "    net,\n",
    "    mask,\n",
    "    template=lfx.ModuleReconstructor(lfx.LinearAffine(rngs=nnx.Rngs(0)))\n",
    "):\n",
    "    if not isinstance(mask, lfx.BinaryMask):\n",
    "        mask = lfx.BinaryMask.from_boolean_mask(mask)\n",
    "\n",
    "    return lfx.GeneralCouplingLayer(net, mask, template, split=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c2a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_flow = lfx.Chain(\n",
    "    masked_affine_coupling(\n",
    "        nnx.Sequential(lambda x: x[..., None], lfx.SimpleConvNet(1, 2, rngs=rngs)),\n",
    "        lfx.checker_mask(space_shape, True)),\n",
    "    masked_affine_coupling(\n",
    "        nnx.Sequential(lambda x: x[..., None], lfx.SimpleConvNet(1, 2, rngs=rngs)),\n",
    "        lfx.checker_mask(space_shape, False)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f6dbb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1, 16, 16), (1,))\n"
     ]
    }
   ],
   "source": [
    "%shapes affine_flow.forward(np.ones((1, 16, 16)), jnp.zeros((1,)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
